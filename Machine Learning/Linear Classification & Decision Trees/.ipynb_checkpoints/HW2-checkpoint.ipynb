{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black'>EE25737: Introduction to Machine Learning</font>\n",
    "## <font color='black'>Fall 99-00, Group 2</font>\n",
    "## Problem C3: Linear Classification & Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [your name]\n",
    "### [your ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you will implement linear classification algorithms (perceptron and linear support vector machines), and decision trees.<br>\n",
    "Answer the questions in your report, which should not exceed three pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. Load Data\n",
    "In this section, you are given a data set <code>data_banknote_authentication.csv</code> with two classes ($y = 1$, $y = -1$). Each data point has four features obtained from digital image processing of fake and real banknotes, and a label $y=1$ for real backnotes, and $y=-1$ for faked ones. The first four columns are training features and the last column is the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into two parts. The first <code>80%</code> of the data is for training and the remaining <code>20%</code> for testing.<br>\n",
    "Import data with pandas library.\n",
    "The first 4 columns are training features, denoted by $x_1, x_2, x_3, x_4$, and the 5th column is the label, denoted by $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code to load data\n",
    "\n",
    "# X = ...\n",
    "# Y = ...\n",
    "\n",
    "\n",
    "\n",
    "# Your code to split the data (with no randomization)\n",
    "\n",
    "\n",
    "# X_train = ...\n",
    "# Y_train = ...\n",
    "\n",
    "\n",
    "# X_test = ...\n",
    "# Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you should implement the perceptron algorithm from the scratch. First, add one dimension with <code>constant 1</code> to each data point (i.e. $x_0 = 1$). What is the purpose of this? <br>\n",
    "Perform the algorithm for <code>50000</code> iterations, and at each <code>500</code> iterations calculate and save the error ($\\frac{1}{n}\\sum_{i=1}^{n} \\boldsymbol{1}_{prediction_{i}\\neq y_i}$) on the test data, and in the end plot the error against the number of iterations. After the end of the training process, report the final error on the test data and the final weights <code><bold>w</bold></code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement the algorithm here\n",
    "\n",
    "def perceptron(X_tr, Y_tr, X_te, Y_te, max_iter=50000):\n",
    "    \n",
    "    w = 0\n",
    "    loss_history = list()\n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "            # Your code\n",
    "        \n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    \n",
    "    return w, loss_history\n",
    "\n",
    "## train of training samples\n",
    "\n",
    "# w, loss_history = perceptron(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "final_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot test error over every 500 iterations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Generalize to non-linear classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map data (train and test) $x$ by $\\psi(.)$ to the six-dimensional $x'$ as follows:\n",
    "$$x = (x_0, x_1, x_2, x_3, x_4) \\overset{\\psi}{\\implies} x' = (x_0, x_1, x_2, x_3, x_4, x_4^3)$$\n",
    "Apply Perceptron to $x'$ and repeat part A2.<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code to train on x'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot error on x'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. SVM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SVM model on the data. In this part of the problem, you should use built-in models of libraries like [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) for training and predicting labels of the data. Do not change the default parameters of the model excpet $max\\_iter$  if it is needed.  Note that you should train the model on the pure form of $x$ (without the added feature $x_0=1$). At last, report final error ($\\frac{1}{n}\\sum_{i=1}^{n} \\boldsymbol{1}_{prediction_{i}\\neq y_i}$) on the training and the test samples, and final weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train a SVM model, report final errors\n",
    "\n",
    "emp_loss, true_loss = 0, 0\n",
    "weights = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5. SVM Algorithm on $\\psi(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the SVM model on the mapped data $x'$. Report the final weight vector, the final error on the training data, and the final error on the test data. Again, for training the model with libraries, the added feature $x'_0=1$ should not be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train a SVM model, report final errors\n",
    "\n",
    "\n",
    "emp_loss, true_loss = 0, 0\n",
    "weights = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discuss and compare the resulting weights and errors ($\\frac{1}{n}\\sum_{i=1}^{n} \\boldsymbol{1}_{prediction_{i}\\neq y_i}$) of the above methods in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset <code>mushrooms.csv</code> includes the overall features of some population of mushrooms. Each data point has <code>22</code> features (e.g. habitat, size, color, etc.) and the goal is to classify mushrooms as poisonous ($y=0$) or edible ($y=1$), by using Decision Trees classifiers. Use built-in models of libraries in [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for training and predicting labels of the data. Do not change the default parameters of the model excpet $max\\_depth$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Load Data\n",
    "The first cloumn is the label, and the remaining <code>22</code> columns are features of data points. Split the data into three sets: the first <code>70%</code> for training, the next <code>20%</code> for verification, and the remaining <code>10%</code> for testing. The validation set is for choosing the best model among all models based on the error ($\\frac{1}{n}\\sum_{i=1}^{n} \\boldsymbol{1}_{prediction_{i}\\neq y_i}$). The test set is for estimating the true error of the selected model.<br>\n",
    "Import data with pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code to load data\n",
    "\n",
    "# X = ...\n",
    "# Y = ...\n",
    "\n",
    "\n",
    "\n",
    "# Your code to split the data (with no randomization)\n",
    "\n",
    "\n",
    "# X_train = ...\n",
    "# Y_train = ...\n",
    "\n",
    "\n",
    "# X_val = ...\n",
    "# Y_val = ...\n",
    "\n",
    "\n",
    "# X_test = ...\n",
    "# Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Train Desicion Tree\n",
    "Set the <code>maximum depth</code> of the tree to $\\{4, 6, 8, 10, 12, 14, 16, 18, 20\\}$. For each maximum depth, train a classifier on the training data and report the resulting loss on the validation set. Plot the loss against the maximum depth. What is the best maximum depth?<br>\n",
    "Finally, for the best maximum depth, report the loss on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train Desicion Tree for each depth here\n",
    "\n",
    "depth_tree = [4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot validation errors over the depth of trees, and explain your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Implement the figure here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
