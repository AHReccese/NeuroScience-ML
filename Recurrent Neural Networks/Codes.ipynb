{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            #review\n",
    "            One-hidden layer Neural network \n",
    "'''\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, learning_rate):\n",
    "\n",
    "        super(Net, self).__init__()  # one hidden layer\n",
    "        self.inputSize = input_size\n",
    "        self.outputSize = output_size\n",
    "        self.hiddenSize = hidden_size\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_error = 1\n",
    "        self.previous_error = 0\n",
    "        self.netLog = []\n",
    "\n",
    "        self.last_step = 1\n",
    "        self.dynamic_learning_rate = 1\n",
    "        self.learning_gradient = 1\n",
    "        self.previous_learning_gradient = 1\n",
    "\n",
    "        # weights initialize\n",
    "        self.neuronLog = []\n",
    "        self.W1 = torch.randn(self.inputSize, self.hiddenSize)  # i X h tensor\n",
    "        self.W2 = torch.randn(self.hiddenSize, self.outputSize)  # h X o tensor\n",
    "        return\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        self.z1 = torch.matmul(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z1)  # activation function\n",
    "        self.updateNeuronLog(self.z2)\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "\n",
    "        # o = self.z3\n",
    "        o = self.sigmoid(self.z3)\n",
    "        return o\n",
    "\n",
    "    def sigmoid(self, s):\n",
    "        # sigmoid function\n",
    "        return (1 / (1 + torch.exp(-s)))\n",
    "\n",
    "    def relu(self, s):\n",
    "        # ramp function\n",
    "        s[s != s] = 0\n",
    "        return (s + torch.abs(s)) / 2\n",
    "\n",
    "    def reluPrime(self, s):\n",
    "        # derivative of ramp function\n",
    "        return self.relu(s / torch.abs(s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        # derivative of sigmoid function\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def backward(self, X, y, o):\n",
    "\n",
    "        self.o_error = y - o  # error in output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)  # derivative of relu to error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta) * self.learning_rate\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta) * self.learning_rate\n",
    "        self.current_error = torch.mean(torch.abs(self.o_error))\n",
    "        self.updateLog()\n",
    "\n",
    "        self.learning_gradient = (self.previous_error - self.current_error) / self.previous_error\n",
    "        if self.dynamic_learning_rate == 1 and self.previous_error != 0:\n",
    "\n",
    "            if self.learning_gradient > self.previous_learning_gradient:\n",
    "                self.learning_rate = self.learning_rate / 1.1\n",
    "                # self.last_step = self.last_step / 2\n",
    "            else:\n",
    "                self.learning_rate = self.learning_rate * 1.1\n",
    "                # self.last_step = 1\n",
    "\n",
    "        self.previous_learning_gradient = self.learning_gradient\n",
    "        self.previous_error = self.current_error\n",
    "        return\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # forward + backward pass for training\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        # print(self.W1, '\\n', self.W2)\n",
    "        return\n",
    "\n",
    "    def saveWeights(self, model, address):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, address)\n",
    "        # torch.load(address)\n",
    "        return\n",
    "\n",
    "    def updateLog(self):\n",
    "        self.netLog.append([self.current_error * 10, self.learning_rate, self.learning_gradient])\n",
    "        return\n",
    "\n",
    "    def getLog(self):\n",
    "        outlog = np.array(self.netLog)\n",
    "        return outlog\n",
    "\n",
    "    def updateNeuronLog(self, hidden_neurons_log):\n",
    "        self.neuronLog.append([np.array(hidden_neurons_log)])\n",
    "        return\n",
    "\n",
    "    def getNeuronLog(self):\n",
    "        return self.neuronLog\n",
    "\n",
    "    def setLearningRate(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        return\n",
    "\n",
    "    def setDynamicLearningRate(self, dynamic_learning_rate):\n",
    "        self.dynamic_learning_rate = dynamic_learning_rate\n",
    "        return\n",
    "\n",
    "    def setTrain(self, training_sample_input, training_sample_output, batch_size, epoches_number, learning_rate,\n",
    "                 dynamic_learning_rate):\n",
    "\n",
    "        self.setLearningRate(learning_rate)\n",
    "        self.setDynamicLearningRate(dynamic_learning_rate)\n",
    "        X1 = []\n",
    "        Y1 = []\n",
    "\n",
    "        for i in range(0, batch_size):\n",
    "            X1.append(training_sample_input)\n",
    "            Y1.append(training_sample_output)\n",
    "\n",
    "        X1 = torch.cat(X1, 0)\n",
    "        Y1 = torch.cat(Y1, 0)\n",
    "        for i in range(0, epoches_number):\n",
    "            self.train(X1, Y1)\n",
    "\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGING THE NEURAL_NETWORK CODE INTO MORE SIMPLER ONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # weights initialize\n",
    "        self.inpHid1 = nn.Linear(input_size, hidden_size)\n",
    "        self.hid1Hid2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hid2Out = nn.Linear(hidden_size, output_size)\n",
    "        self.activationFunction = nn.Tanh()\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        # someHow as \n",
    "        a = 0.5\n",
    "        \n",
    "        # input * weights == firstLayer ...\n",
    "        # firtsLayer * Function(sigmond funtion instead u(t)) --> input for hiddenLayer\n",
    "        # HiddenLayer * secondWeights \n",
    "        # afterHiddenLayer * Function(Sigmond function instead u(t)) --> final output\n",
    "        \n",
    "        # according to the formula.\n",
    "        hidden = self.activationFunction((1-a)*hidden + a*self.inpHid1(input) + a*self.hid1Hid2(nn.functional.relu(hidden)))\n",
    "        output = self.activationFunction(self.hid2Out(hidden))\n",
    "        return output, hidden\n",
    "\n",
    "    def backProp(self):\n",
    "        # creating  backpropagation matrix\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#   Task one \n",
    "#   perceptual decision making.\n",
    "#\n",
    "#\n",
    "def decision_making_dataset(DC_value1, DC_value2, Input_size, Noise_amplitude, N, DC_val_opt):\n",
    "    \n",
    "    if DC_val_opt==1:\n",
    "        Inp1 = DC_value1 + Noise_amplitude*(torch.rand(1,Input_size,N)-0.5)\n",
    "        Inp2 = DC_value2 + Noise_amplitude*(torch.rand(1,Input_size,N)-0.5)\n",
    "        Inp = torch.cat((Inp1,Inp2),0)\n",
    "        Output = torch.zeros(1,2,N)\n",
    "        if DC_value2 > DC_value1 :\n",
    "            Output[0,1,:]=1\n",
    "        else:\n",
    "            Output[0,0,:]=1\n",
    "    else:\n",
    "        Inp1 = Noise_amplitude*(torch.rand(1,Input_size,N)-0.5)\n",
    "        Inp2 = Noise_amplitude*(torch.rand(1,Input_size,N)-0.5)\n",
    "        for j in range(N):\n",
    "            Inp1[0,:,j] = np.random.randint(1,10) + Inp1[0,:,j]\n",
    "            Inp2[0,:,j] = np.random.randint(1,10) + Inp2[0,:,j]\n",
    "            \n",
    "        Inp = torch.cat((Inp1,Inp2),0)\n",
    "        Output = torch.zeros(1,2,N)\n",
    "        for i in range(N):\n",
    "            if torch.mean(Inp1[0,:,i]) < torch.mean(Inp2[0,:,i]) :\n",
    "                Output[0,1,i]=1\n",
    "            else:\n",
    "                Output[0,0,i]=1\n",
    "    Output = Output.squeeze()\n",
    "    return Inp,Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataset Creation\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "X,Y = decision_making_dataset(DC_value1=1, DC_value2=5, Input_size=1, Noise_amplitude=1, N=8, DC_val_opt=1)\n",
    "print(X.size())\n",
    "plt.figure\n",
    "plt.plot(X[0,0,:].numpy())\n",
    "plt.plot(X[1,0,:].numpy())\n",
    "plt.show()\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first implementation\n",
    "def predictor(output,N):\n",
    "    out = torch.zeros(2,N)\n",
    "    for i in range(N):\n",
    "        if (output[0,i]>output[1,i]):\n",
    "            out[0,i] = 1\n",
    "            out[1,i] = 0\n",
    "        else:\n",
    "            out[0,i] = 0\n",
    "            out[1,i] = 1\n",
    "    return out\n",
    "    \n",
    "    return (output>0.5).double()\n",
    "\n",
    "def pdm_task1 (learning_rate, hidden_size, batch_size, number_of_epochs, sequence_length=10, dataset_size = 100):\n",
    "\n",
    "    rnn = RNN(input_size=2, hidden_size=hidden_size, output_size=2)\n",
    "    \n",
    "    L = sequence_length\n",
    "    \n",
    "    N = dataset_size\n",
    "    \n",
    "    num_of_batches = int(N/batch_size)\n",
    "    \n",
    "#     input, target = parity_generator(N,L)\n",
    "    input, target = decision_making_dataset(DC_value1=1, DC_value2=1.1, Input_size=L, Noise_amplitude=0.2, N=N, DC_val_opt=0)\n",
    "    \n",
    "    epochs_samples = np.zeros(int(number_of_epochs/20))\n",
    "    \n",
    "    epoch_loss = np.zeros(int(number_of_epochs/20))\n",
    "\n",
    "\n",
    "    for epochs in range(number_of_epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        learning_rate = 0.005\n",
    "\n",
    "        #optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "        OUT = torch.tensor(np.zeros((2, N)))\n",
    "\n",
    "        for i in range (N):\n",
    "            hidden = rnn.backProp()\n",
    "            \n",
    "            for j in range (L):\n",
    "                output, hidden = rnn.forward(input[:,j,i], hidden)\n",
    "            loss = criterion(output.float(), target[:,i].unsqueeze(0))\n",
    "            if(epochs == number_of_epochs-1):\n",
    "                OUT[:,i] = output;\n",
    "            loss.backward()\n",
    "            if (N%batch_size==0):\n",
    "                optimizer.step()\n",
    "                \n",
    "                for j in range (hidden_size):\n",
    "                    list(rnn.hid1Hid2.parameters())[0].data[j, j].data.copy_(torch.tensor(0))\n",
    "                    for i in range (hidden_size):\n",
    "                        sign = 1\n",
    "                        if j >= hidden_size * 4 / 5:\n",
    "                            sign = -1\n",
    "                        if (list(rnn.hid1Hid2.parameters())[0].data[i, j].item() * sign < 0):\n",
    "                            list(rnn.hid1Hid2.parameters())[0].data[i, j].data.copy_(torch.tensor(0))\n",
    "\n",
    "                \n",
    "                rnn.zero_grad()        \n",
    "        \n",
    "        if (epochs%20==19):\n",
    "            print('epoch=',epochs+1, ', loss=', loss.item())\n",
    "            number = int(epochs/20)\n",
    "            epochs_samples[number] = epochs\n",
    "            epoch_loss[number] = loss.item()\n",
    "\n",
    "    print('convergance to truth! = ',100*torch.sum(predictor(OUT,N)[0,:]==target[0,:]).item()/N)\n",
    "\n",
    "    plt.figure\n",
    "    plt.plot(epochs_samples, epoch_loss)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "    s = (rnn.hid1Hid2.weight.data)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "    plt.title('Weight Matrix')\n",
    "    plt.xlabel('length increase')\n",
    "    plt.ylabel('percentage')\n",
    "    plt.show()\n",
    "\n",
    "    number_of_tests = 100\n",
    "    \n",
    "    true_percentage = np.zeros(10)\n",
    "    \n",
    "    for k in range(10):\n",
    "        delta = 0.2*(k+1)\n",
    "        test_input, test_target = decision_making_dataset(DC_value1=1, DC_value2=1+delta, Input_size=L, Noise_amplitude=1, N = number_of_tests, DC_val_opt=1)\n",
    "\n",
    "        test_OUT = torch.tensor(np.zeros((2, number_of_tests)))\n",
    "\n",
    "        hidden = rnn.backProp()\n",
    "        for test in range (number_of_tests):\n",
    "            hidden = rnn.backProp()\n",
    "            for i in range (L):\n",
    "                rnn.zero_grad()\n",
    "                output, hidden = rnn(test_input[:,i,test], hidden)\n",
    "                if(test == number_of_tests-1):\n",
    "                    print(output)\n",
    "            test_OUT[:,test] = output\n",
    "\n",
    "        true_percentage[k] = 100*torch.sum(predictor(test_OUT,number_of_tests)[0,:]==test_target[0,:]).item()/number_of_tests\n",
    "        print('convergance to truth! = ',true_percentage[k])\n",
    "        \n",
    "    plt.figure\n",
    "    plt.plot(true_percentage)\n",
    "    plt.title('convergance to truth!')\n",
    "    plt.xlabel('length increase')\n",
    "    plt.ylabel('percentage')\n",
    "    plt.show()\n",
    "        \n",
    "    return true_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_percentage = np.zeros([10,10])\n",
    "for i in range (10):\n",
    "    true_percentage[i,:] = pdm_task1 (learning_rate=0.05, hidden_size=10, batch_size=50, number_of_epochs=100, sequence_length=i+1, dataset_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "for i in range (1,10):\n",
    "    plt.plot(true_percentage[i,:],label = 'stimulus length'+str(i))\n",
    "plt.title('input size & input length effect')\n",
    "plt.legend('123456789')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1 : Second Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(output,N):\n",
    "    out = torch.zeros(2,N)\n",
    "    for i in range(N):\n",
    "        if (output[0,i]>output[1,i]):\n",
    "            out[0,i] = 1\n",
    "            out[1,i] = 0\n",
    "        else:\n",
    "            out[0,i] = 0\n",
    "            out[1,i] = 1\n",
    "    return out\n",
    "\n",
    "    return (output>0.5).double()\n",
    "\n",
    "def pdm_task2 (learning_rate, hidden_size, batch_size, number_of_epochs, sequence_length=10, dataset_size = 100):\n",
    "\n",
    "    rnn = RNN(input_size=2, hidden_size=hidden_size, output_size=2)\n",
    "    \n",
    "    L = sequence_length\n",
    "    \n",
    "    N = dataset_size\n",
    "    \n",
    "    num_of_batches = int(N/batch_size)\n",
    "    \n",
    "#     input, target = parity_generator(N,L)\n",
    "    input, target = decision_making_dataset(DC_value1=1, DC_value2=1.1, Input_size=L, Noise_amplitude=0.2, N=N, DC_val_opt=0)\n",
    "    \n",
    "    epochs_samples = np.zeros(int(number_of_epochs/20))\n",
    "    \n",
    "    epoch_loss = np.zeros(int(number_of_epochs/20))\n",
    "\n",
    "\n",
    "    for epochs in range(number_of_epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        learning_rate = 0.005\n",
    "\n",
    "        #optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "        OUT = torch.tensor(np.zeros((2, N)))\n",
    "        \n",
    "        temp_out = torch.zeros(2,L)\n",
    "        for i in range (N):\n",
    "            hidden = rnn.backProp()\n",
    "            \n",
    "            for j in range (L):\n",
    "                output, hidden = rnn.forward(input[:,j,i], hidden)\n",
    "                if (output[0,0]>output[0,1]):\n",
    "                    temp_out[0,j] = 1\n",
    "                    temp_out[1,j] = 0\n",
    "                else:\n",
    "                    temp_out[0,j] = 0\n",
    "                    temp_out[1,j] = 1\n",
    "#                 temp_out[:,j] = predictor(output,1)\n",
    "                if (j>1 and temp_out[0,j] == temp_out[0,j-1] and temp_out[0,j] == temp_out[0,j-2]):\n",
    "                    break\n",
    "            loss = criterion(output.float(), target[:,i].unsqueeze(0))\n",
    "            if(epochs == number_of_epochs-1):\n",
    "                OUT[:,i] = output;\n",
    "#                 print(output.data.numpy())\n",
    "            loss.backward()\n",
    "            if (N%batch_size==0):\n",
    "                optimizer.step()\n",
    "                \n",
    "                for j in range (hidden_size):\n",
    "                    list(rnn.hid1Hid2.parameters())[0].data[j, j].data.copy_(torch.tensor(0))\n",
    "                    for i in range (hidden_size):\n",
    "                        sign = 1\n",
    "                        if j >= hidden_size * 4 / 5:\n",
    "                            sign = -1\n",
    "                        if (list(rnn.hid1Hid2.parameters())[0].data[i, j].item() * sign < 0):\n",
    "                            list(rnn.hid1Hid2.parameters())[0].data[i, j].data.copy_(torch.tensor(0))\n",
    "\n",
    "                \n",
    "                rnn.zero_grad()        \n",
    "        \n",
    "        if (epochs%20==19):\n",
    "            print('epoch=',epochs+1, ', loss=', loss.item())\n",
    "            number = int(epochs/20)\n",
    "            epochs_samples[number] = epochs\n",
    "            epoch_loss[number] = loss.item()\n",
    "    print(predictor(OUT,N))\n",
    "    print(target)\n",
    "    print('true percentage on train set = ',100*torch.sum(predictor(OUT,N)[0,:]==target[0,:]).item()/N)\n",
    "\n",
    "    plt.figure\n",
    "    plt.plot(epochs_samples, epoch_loss)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "    s = (rnn.hid1Hid2.weight.data)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "    plt.title('Weight Matrix')    \n",
    "    plt.show()\n",
    "    \n",
    "    number_of_tests = 100\n",
    "    \n",
    "    test_OUT = torch.tensor(np.zeros((2, number_of_tests)))\n",
    "    \n",
    "    reaction_time = np.zeros(10)\n",
    "    true_percentage = np.zeros(10)\n",
    "    \n",
    "    for k in range(10):\n",
    "        test_input, test_target = decision_making_dataset(DC_value1=1, DC_value2=1.5+0.5*k, Input_size=L, Noise_amplitude=2, N = number_of_tests, DC_val_opt=1)\n",
    "        rt = np.zeros(number_of_tests)\n",
    "        hidden = rnn.backProp()\n",
    "        for test in range (number_of_tests):\n",
    "            hidden = rnn.backProp()\n",
    "            for i in range (L):\n",
    "                rnn.zero_grad()\n",
    "                output, hidden = rnn(test_input[:,i,test], hidden)\n",
    "                if (output[0,0]>output[0,1]):\n",
    "                        temp_out[0,i] = 1\n",
    "                        temp_out[1,i] = 0\n",
    "                else:\n",
    "                    temp_out[0,i] = 0\n",
    "                    temp_out[1,i] = 1\n",
    "                if (i>1 and temp_out[0,i] == temp_out[0,i-1] and temp_out[0,i] == temp_out[0,i-2]):\n",
    "                    rt[test] = i\n",
    "                    break\n",
    "\n",
    "            test_OUT[:,test] = output\n",
    "            reaction_time[k] = np.mean(rt)\n",
    "            true_percentage[k] = 100*torch.sum(predictor(test_OUT,number_of_tests)[0,:]==test_target[0,:]).item()/number_of_tests\n",
    "\n",
    "    plt.figure\n",
    "    plt.plot(reaction_time)\n",
    "    plt.title('timeReacted')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure\n",
    "    plt.plot(true_percentage)\n",
    "    plt.title('convergance to truth')\n",
    "    plt.show()\n",
    "       \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdm_task2 (learning_rate=0.05, hidden_size=10, batch_size=50, number_of_epochs=100, sequence_length=20, dataset_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 : parametric working memory.\n",
    "# creating data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_dataset(DC_value1, DC_value2, Noise_amplitude, N, DC_val_opt):\n",
    "    X = torch.zeros(N,25)\n",
    "    output = torch.zeros(N,2)\n",
    "    if DC_val_opt == 1:\n",
    "        for i in range (N):\n",
    "            X[i,5:10] = DC_value1\n",
    "            k = np.random.randint(3,8)\n",
    "            X[i,10+k:15+k] = DC_value2\n",
    "            if (DC_value2 > DC_value1):\n",
    "                output[i,1] = 1\n",
    "            else:\n",
    "                output[i,0] = 1\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            a1 = np.random.randint(1,10)\n",
    "            a2 = np.random.randint(1,10)\n",
    "            if (a1==a2):\n",
    "                a1=a1+1\n",
    "            X[i,5:10] = a1\n",
    "            k = np.random.randint(3,8)\n",
    "            X[i,10+k:15+k] = a2\n",
    "            if (a2 > a1):\n",
    "                output[i,1] = 1\n",
    "            else:\n",
    "                output[i,0] = 1       \n",
    "    X = X + Noise_amplitude*(torch.rand(N,25)-0.5)\n",
    "    return X, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2 : Dataset Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, output = frequency_dataset(DC_value1=2, DC_value2=2.2, Noise_amplitude=0.2, N=10, DC_val_opt=0)\n",
    "plt.figure\n",
    "plt.plot(X[0,:].numpy())\n",
    "plt.title('Merged firstInp & secondInp')\n",
    "plt.show()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2 : Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(output,N):\n",
    "    out = torch.zeros(N,2)\n",
    "    for i in range(N):\n",
    "        if (output[i,0]>output[i,1]):\n",
    "            out[i,0] = 1\n",
    "            out[i,1] = 0\n",
    "        else:\n",
    "            out[i,0] = 0\n",
    "            out[i,1] = 1\n",
    "    return out\n",
    "    \n",
    "    return (output>0.5).double()\n",
    "\n",
    "def frequency_task (learning_rate, hidden_size, batch_size, number_of_epochs, dataset_size = 100):\n",
    "\n",
    "    rnn = RNN(input_size=1, hidden_size=hidden_size, output_size=2)\n",
    "        \n",
    "    N = dataset_size\n",
    "    \n",
    "    num_of_batches = int(N/batch_size)\n",
    "    \n",
    "    input, target = frequency_dataset(DC_value1=2, DC_value2=3, Noise_amplitude=0.2, N=N, DC_val_opt=0)\n",
    "    \n",
    "    epochs_samples = np.zeros(int(number_of_epochs/20))\n",
    "    \n",
    "    epoch_loss = np.zeros(int(number_of_epochs/20))\n",
    "\n",
    "\n",
    "    for epochs in range(number_of_epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        learning_rate = 0.005\n",
    "\n",
    "        optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "        OUT = torch.tensor(np.zeros((N, 2)))\n",
    "\n",
    "        for i in range (N):\n",
    "            hidden = rnn.backProp()\n",
    "            \n",
    "            for j in range (25):\n",
    "                output, hidden = rnn.forward(input[i,j].unsqueeze(0), hidden)\n",
    "#             print(output.size())\n",
    "#             print(target[:,i].unsqueeze(0).size())\n",
    "            loss = criterion(output.float(), target[i,:].unsqueeze(0))\n",
    "            if(epochs == number_of_epochs-1):\n",
    "                OUT[i,:] = output;\n",
    "#                 print(output.data.numpy())\n",
    "            loss.backward()\n",
    "            if (N%batch_size==0):\n",
    "                optimizer.step()\n",
    "                \n",
    "                for j in range (hidden_size):\n",
    "                    list(rnn.hid1Hid2.parameters())[0].data[j, j].data.copy_(torch.tensor(0))\n",
    "                    for i in range (hidden_size):\n",
    "                        sign = 1\n",
    "                        if j >= hidden_size * 4 / 5:\n",
    "                            sign = -1\n",
    "                        if (list(rnn.hid1Hid2.parameters())[0].data[i, j].item() * sign < 0):\n",
    "                            list(rnn.hid1Hid2.parameters())[0].data[i, j].data.copy_(torch.tensor(0))\n",
    "\n",
    "                \n",
    "                rnn.zero_grad()        \n",
    "        \n",
    "        if (epochs%20==19):\n",
    "            print('epoch=',epochs+1, ', loss=', loss.item())\n",
    "            number = int(epochs/20)\n",
    "            epochs_samples[number] = epochs\n",
    "            epoch_loss[number] = loss.item()\n",
    "    \n",
    "    plt.figure\n",
    "    plt.plot(epochs_samples, epoch_loss)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "\n",
    "    s = (rnn.hid1Hid2.weight.data)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "    plt.title('Weight Matrix')    \n",
    "    plt.show()\n",
    "    \n",
    "    print('convergance to truth TrainMode',100*torch.sum(predictor(OUT,N)[:,0]==target[:,0]).item()/N)\n",
    "\n",
    "    number_of_tests = 100\n",
    "    \n",
    "    true_percentage = np.zeros(20)\n",
    "    for k in range (20):\n",
    "        delta = (k+1)*0.5\n",
    "        \n",
    "        test_input, test_target = frequency_dataset(DC_value1=2, DC_value2=2+delta, Noise_amplitude=0.2, N = number_of_tests, DC_val_opt=1)\n",
    "\n",
    "        test_OUT = torch.tensor(np.zeros((number_of_tests,2)))\n",
    "\n",
    "        hidden = rnn.backProp()\n",
    "        for test in range (number_of_tests):\n",
    "            hidden = rnn.init_hidden()\n",
    "            for i in range (25):\n",
    "                rnn.zero_grad()\n",
    "                output, hidden = rnn(test_input[test,i].unsqueeze(0), hidden)\n",
    "\n",
    "            test_OUT[test,:] = output\n",
    "            \n",
    "        true_percentage[k] = 100*torch.sum(predictor(test_OUT,number_of_tests)[:,0]==test_target[:,0]).item()/number_of_tests\n",
    "\n",
    "        print('convergance to truth',delta,' is ',true_percentage[k])\n",
    "    delta = np.linspace(0.5,10,num=20)\n",
    "    plt.figure\n",
    "    plt.plot(delta, true_percentage)\n",
    "    plt.title('convergance to truth')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_task (learning_rate=0.05, hidden_size=5, batch_size=20, number_of_epochs=200, dataset_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3 : Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_movement(seq_num, partial_seq_len, test_without_marker=0):\n",
    "    L = partial_seq_len*5\n",
    "    X = torch.zeros(17, L)\n",
    "    out = torch.zeros(2, L)\n",
    "    X[4,partial_seq_len:2*partial_seq_len] = 1    \n",
    "    if (seq_num == 1):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[5,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[2,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[9,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "\n",
    "    if (seq_num == 2):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[3,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[2,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[10,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = -1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "\n",
    "    if (seq_num == 3):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[3,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[6,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[7,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[8,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[11,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = -1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = -1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "\n",
    "\n",
    "    if (seq_num == 4):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[5,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[6,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[7,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[8,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[12,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = -1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "\n",
    "\n",
    "    if (seq_num == 5):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[5,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[2,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[13,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "\n",
    "\n",
    "    if (seq_num == 6):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[3,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[2,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[14,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = -1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "\n",
    "\n",
    "    if (seq_num == 7):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[3,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[6,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[7,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[8,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[15,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = -1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = -1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "\n",
    "\n",
    "    if (seq_num == 8):\n",
    "        X[4,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[5,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        X[3,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        \n",
    "        X[5,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[1,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        X[7,3*partial_seq_len:4*partial_seq_len] = 1\n",
    "        \n",
    "        X[6,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[7,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        X[8,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        X[16,:] = 1\n",
    "        \n",
    "        out[0,2*partial_seq_len:3*partial_seq_len] = 1\n",
    "        out[0,3*partial_seq_len:4*partial_seq_len] = 0\n",
    "        out[0,4*partial_seq_len:5*partial_seq_len] = 1\n",
    "        \n",
    "        out[1,2*partial_seq_len:3*partial_seq_len] = 0\n",
    "        out[1,3*partial_seq_len:4*partial_seq_len] = -1\n",
    "        out[1,4*partial_seq_len:5*partial_seq_len] = -1\n",
    "    \n",
    "    if (test_without_marker==1):\n",
    "        X[9:,:] = 0\n",
    "\n",
    "    return X, out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3 : Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_movement_nn (learning_rate, hidden_size, batch_size, number_of_epochs, sequence_length=10, dataset_size = 100, test_without_marker = 0):\n",
    "\n",
    "    rnn = RNN(input_size=17, hidden_size=hidden_size, output_size=2)\n",
    "    \n",
    "    L = int(sequence_length/5)\n",
    "    \n",
    "    N = dataset_size\n",
    "    \n",
    "    num_of_batches = int(N/batch_size)\n",
    "    \n",
    "    \n",
    "    #input, target = eye_movement(seq_num, L)\n",
    "        \n",
    "    epochs_samples = np.zeros(int(number_of_epochs/20))\n",
    "    \n",
    "    epoch_loss = np.zeros(int(number_of_epochs/20))\n",
    "\n",
    "\n",
    "    for epochs in range(number_of_epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        learning_rate = 0.005\n",
    "\n",
    "        #optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "        optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "        OUT = torch.tensor(np.zeros((2, sequence_length)))\n",
    "\n",
    "        for i in range (N):\n",
    "            hidden = rnn.backProp()\n",
    "            input, target = eye_movement(seq_num = 1 + i%8, partial_seq_len = L)\n",
    "            for j in range (sequence_length):\n",
    "                output, hidden = rnn.forward(input[:,j], hidden)\n",
    "                loss = criterion(output.float(), target[:,j].unsqueeze(0))\n",
    "            \n",
    "                if(epochs == number_of_epochs-1):\n",
    "                    OUT[:,j] = output;\n",
    "                loss.backward(retain_graph=True)\n",
    "            if (N%batch_size==0):\n",
    "                optimizer.step()\n",
    "                \n",
    "                for j in range (hidden_size):\n",
    "                    list(rnn.hid1Hid2.parameters())[0].data[j, j].data.copy_(torch.tensor(0))\n",
    "                    for i in range (hidden_size):\n",
    "                        sign = 1\n",
    "                        if j >= hidden_size * 4 / 5:\n",
    "                            sign = -1\n",
    "                        if (list(rnn.hid1Hid2.parameters())[0].data[i, j].item() * sign < 0):\n",
    "                            list(rnn.hid1Hid2.parameters())[0].data[i, j].data.copy_(torch.tensor(0))\n",
    "                \n",
    "                rnn.zero_grad()        \n",
    "        \n",
    "        if (epochs%20==19):\n",
    "            print('epoch=',epochs+1, ', loss=', loss.item())\n",
    "            number = int(epochs/20)\n",
    "            epochs_samples[number] = epochs\n",
    "            epoch_loss[number] = loss.item()\n",
    "            \n",
    "    plt.figure\n",
    "    plt.plot(epochs_samples, epoch_loss)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    \n",
    "            \n",
    "    plt.figure\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(OUT[0,:].detach().numpy(),label='output')\n",
    "    plt.plot(target[0,:].detach().numpy(),label='target')\n",
    "    plt.ylim([-1.5,1.5])\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('x')\n",
    "    plt.legend()\n",
    "    plt.title('Train')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(OUT[1,:].detach().numpy(),label='output')\n",
    "    plt.plot(target[1,:].detach().numpy(),label='target')\n",
    "    plt.ylim([-1.5,1.5])\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    s = (rnn.hid1Hid2.weight.data)\n",
    "    plt.figure()\n",
    "    plt.imshow(s)\n",
    "    plt.title('Weight Matrix')    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    number_of_tests = 8\n",
    "    \n",
    "    for i in range(number_of_tests):\n",
    "        test_input, test_target = eye_movement(seq_num = 1 + i, partial_seq_len = L, test_without_marker = test_without_marker)\n",
    "        test_OUT = torch.tensor(np.zeros((2, sequence_length)))\n",
    "        hidden = rnn.backProp()\n",
    "        for j in range (sequence_length):\n",
    "            output, hidden = rnn.forward(test_input[:,j], hidden)\n",
    "            test_OUT[:,j] = output\n",
    "                \n",
    "        plt.figure\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(test_OUT[0,:].detach().numpy(),label='output')\n",
    "        plt.plot(test_target[0,:].detach().numpy(),label='target')\n",
    "        plt.ylim([-1.5,1.5])\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('x')\n",
    "        plt.legend()\n",
    "        plt.title('Test ' + str(i+1))\n",
    "\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(test_OUT[1,:].detach().numpy(),label='output')\n",
    "        plt.plot(test_target[1,:].detach().numpy(),label='target')\n",
    "        plt.ylim([-1.5,1.5])\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3 : Check on larger hidden sized network with full input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_movement_nn(learning_rate=0.05, hidden_size=10, batch_size=10, number_of_epochs=100, sequence_length=20, dataset_size = 100, test_without_marker = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3 : Check on network with non-full input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_movement_nn(learning_rate=0.05, hidden_size=10, batch_size=10, number_of_epochs=100, sequence_length=20, dataset_size = 100, test_without_marker = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
